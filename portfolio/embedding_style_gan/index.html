
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Embedding StyleGAN</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <!-- <meta property="og:image" content="assets/CovNet_teaser.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://jonbarron.info/mipnerf/"/>
    <meta property="og:title" content="mip-NeRF" />
    <meta property="og:description" content="Project page for Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields." /> -->

        <!--TWITTER-->
    <!-- <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="mip-NeRF" />
    <meta name="twitter:description" content="Project page for Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields." />
    <meta name="twitter:image" content="https://jonbarron.info/mipnerf/img/rays_square.png" /> -->


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
	<link rel="icon" href="../../assets/icons/icon-192x192.png">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container-fluid" id="main">
        <div class="row" id="header_project">
            <h2 class="col-md-12 text-center">
                <b>StyleGAN Embedding Algorithms</b>: Image2StyleGAN (I2S) <br>& ImprovedImage2StyleGAN (II2S) <br>
                <small>
                    EEML 2021 (Research Internship & Summer School)
                </small>
            </h2>
        </div>
        <div class="row" id="header_project">
            <div class="col-md-12 text-center">
                <ul class="list-inline" >
                    <li>
                        <a href="https://zosov.github.io/">
                            Oscar Guarnizo
                        </a>
                        </br>Yachay Tech University
                        </br>KAUST
                    </li>
                    <li>
                        <a href="https://peterwonka.net/">
                          Peter Wonka
                        </a>
                        </br>KAUST
                    </li>
                </ul>
            </div>
        </div>


        <div class="row" id="header_project">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://www.researchgate.net/publication/356491906_Reproduction_of_Image2StyleGAN_How_to_Embed_Images_Into_the_StyleGAN_Latent_Space">
                            <image src="assets/icons/mip_paper_image.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>                     
                        <li>
                            <a href="https://github.com/ZosoV/style-gan">
                            <image src="assets/icons/github.png" height="60px" style="filter: invert(1);">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://oscar-guarnizo.medium.com/review-image2stylegan-embedding-an-image-into-stylegan-c7989e345271">
                            <image src="assets/icons/medium.png" height="60px" style="filter: invert(1);">
                                <h4><strong>Blog</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <image src="assets/images/teaser_image.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
                    StyleGAN has demonstrated outstanding contributions due to 
                    the high-quality generated images. As a result, it has 
                    emerged a question, how to embed images into the StyleGAN 
                    latent space? This work tries to answer this question by 
                    studying and reproducing Image2StyleGAN (I2S) and 
                    ImprovedImage2StyleGAN (II2S). These embedding algorithms 
                    compute a latent code for a given input image by optimizing 
                    the latent code that minimizes a loss function. This loss 
                    function is based on perceptual metrics, which capture the 
                    similarity between reference and generated images. Our 
                    reproduction partially replaces the algorithm for further 
                    experimentation of initializers and perceptual losses. 
                    Additionally, we perform some post-image processing 
                    operations such as inpainting, super-resolution, 
                    colorization, morphing, style transfer, and expression 
                    transfer. We verify the behavior of the studied components 
                    and stand out particular concerns.           
                </p>
            </div>
        </div>



        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/0vH1tGhuZbY" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Image2StyleGAN (I2S)
                </h3>
                <p class="text-justify">
                    <a href="https://arxiv.org/abs/1904.03189">Image2StyleGAN by Rameen Abdal et al.</a> is an optimization algorithm that aims to 
                    map a given image (<em>I</em>) into the latent space (<em>w+</em> encoding) of a pre-trained 
                    StyleGAN . These mappings known as latent codes are helpful 
                    to perform posterior image processing applications.
                </p>
                <p style="text-align:center;">
                    <image src="assets/images/equation_i2s.png" class="img-responsive">
                </p>
                
                <!-- <video id="v0" width="100%" autoplay loop muted>
                  <source src="img/pe_anim_horiz.mp4" type="video/mp4" />
                </video> -->
                <p class="text-justify">
                    In order to get the <em>w+</em> embedding, the authors’ 
                    proposed an <strong>optimization framework</strong> based on gradient 
                    descent. The steps are the following:

                    <ol>
                        <li>Start with an initial latent code w* (initial guess).</li>
                        <li>Generate an image with the latent code w*</li>
                        <li>Compare the generated image I* with the reference 
                            image I, using a <strong></strong>loss function.</li>
                        <li>Based on the loss function (error), update the 
                            latent code w* by Gradient Descent.</li>
                        <li>Repeat this process by a given number of iterations.</li>
                    </ol>
                </p>
                <p style="text-align:center;">
                    <image src="assets/images/optimization_framework.png" class="img-responsive">
                </p>
                <p class="text-justify">
                    The optimization process will proceed as follows:
                </p>
                <p style="text-align:center;">
                    <image src="assets/images/progression.png" class="img-responsive">
                </p>
                <p class="text-justify">
                    The <strong>loss function</strong> consists of two terms 
                    a VGG-16 perceptual loss function and means square error (MSE).
                </p>
                <p style="text-align:center;">
                    <image src="assets/images/I2S_loss.png" class="img-responsive">
                </p>
                <p class="text-justify">
                    The <strong>MSE loss</strong> is a standard pixel-wise 
                    error between the generated and reference images.
                    <br> <br>
                    The <strong>perceptual loss</strong> is based on a 
                    pre-trained neural network (VGG-16 trained with ImageNet), 
                    which helps to calculate a similarity between two images 
                    in terms of hidden features. The idea to calculate this 
                    similarity is to send both images through VGG-16 
                    and capture its output feature maps (hidden features) from 
                    different hidden layers.
                </p>
                <p style="text-align:center;">
                    <image src="assets/images/perceptual_loss.png" class="img-responsive">
                </p>
            </div>
        </div>
            


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Improved Image2StyleGAN (II2S)
                </h3>
                <p class="text-justify">
                    <a href="https://arxiv.org/abs/2012.09036">Improved Image2StyleGAN by Peihao Zhu et al.</a> 
                    introduces an additionally normalized space 
                    <em>P</em> to analyze the diversity and the quality 
                    of the reconstructed latent codes. This space can help 
                    answer the question of where good latent codes 
                    are located in latent space. 
                </p>
                <p style="text-align:center;">
                    <image src="assets/images/II2S_scheme.PNG" class="img-responsive center" alt="scales">
                    <figcaption style="text-align:right;">Zhu P. et. al (2021) Improved StyleGAN Embedding: Where are the Good Latents?</figcaption>
                </p>
                <p class="text-justify">
                    Then, the normalized space is used together with a 
                    PCA step to propose a <strong>regularization method</strong>, 
                    which helps to trade off between the reconstruction and image editing
                    capabilities of the algorithm.
                </p>
                <p style="text-align:center;">
                    <image src="assets/images/regularizer.PNG" class="img-responsive" alt="scales">
                </p>
            </div>
        </div>
            


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results
                </h3>
                <p class="text-justify">
                    Using Image2StyleGAN, we studied three semantic image 
                    editing applications: morphing, expression transfer, and style transfer. 
                    Each test can be done by simple latent code manipulation of vectors <em>w</em>.           
                </p>
            </div>
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    <strong>Morphing</strong>
                </p>
            </div>
            <div class="col-md-2 col-md-offset-2">
                <p style="text-align:center; align-items: center;">
                    <image src="assets/images/morphing_gif.png" class="img-responsive" alt="scales">
                </p>
            </div>
            <div class="col-md-6">
                <p style="text-align:center; align-items: center;">
                <image src="assets/images/teaser_image.png" class="img-responsive" alt="scales">
                </p>
            </div>
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    <strong>Expression Transfer</strong>
                </p>
            </div>
            <div class="col-md-2 col-md-offset-2">
                <p style="text-align:center; align-items: center;">
                    <image src="assets/images/expression_transfer_gif.png" class="img-responsive" alt="scales">
                </p>
            </div>
            <div class="col-md-6">
                <p style="text-align:center; align-items: center;">
                <image src="assets/images/expression_transfer_faces.png" class="img-responsive" alt="scales">
                </p>
            </div>
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">

                <p class="text-justify">
                <strong>Style Transfer</strong>            
                </p>
                <p style="text-align:center;">
                    <image src="assets/images/style_transfer.png" class="img-responsive" alt="scales">
                </p>
            </div>
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    Using ImprovedImage2StyleGAN, we studied three editing operations: 
                    colorization, inpainting, and super-resolution.
                </p>
                                        
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    <strong>Colorization</strong>
                </p>
            </div>
 
            <div class="col-md-4 col-md-offset-2">
                <p style="text-align:center; align-items: center;">
                    <image src="assets/images/colorization_left.PNG" class="img-responsive" alt="scales">
                </p>
            </div>
            <div class="col-md-4 ">
                <p style="text-align:center; align-items: center;">
                <image src="assets/images/colorization_right.PNG" class="img-responsive" alt="scales">
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    <strong>Inpainting</strong>
                </p>
            </div>
 
            <div class="col-md-4 col-md-offset-2">
                <p style="text-align:center; align-items: center;">
                    <image src="assets/images/inpainting_left.png" class="img-responsive" alt="scales">
                </p>
            </div>
            <div class="col-md-4 ">
                <p style="text-align:center; align-items: center;">
                <image src="assets/images/inpainting_right.PNG" class="img-responsive" alt="scales">
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    <strong>Super-Resolution</strong>
                </p>
            </div>
 
            <div class="col-md-4 col-md-offset-2">
                <p style="text-align:center; align-items: center;">
                    <image src="assets/images/super_resolution_left.png" class="img-responsive" alt="scales">
                </p>
            </div>
            <div class="col-md-4 ">
                <p style="text-align:center; align-items: center;">
                <image src="assets/images/super_resolution_right.PNG" class="img-responsive" alt="scales">
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Related links
                </h3>
                <p class="text-justify">
                    Image2StyleGAN is an exciting algorithm with a variety 
                    of uses beyond those described here. Bellow, I show some 
                    resources that you find valuable. 
                    <br> <br>
                    - StyleGAN 1: <a href="https://arxiv.org/abs/1812.04948">A Style-Based Generator Architecture for Generative Adversarial Networks</a>.
                    <br> <br>
                    - StyleGAN 2: <a href="https://arxiv.org/abs/1912.04958">Analyzing and Improving the Image Quality of StyleGAN</a>.                    
                    <br> <br>
                    - StyleGAN 2 — Reduced Data: <a href="https://arxiv.org/abs/2006.06676">Training Generative Adversarial Networks with Limited Data</a>.
                    <br> <br>
                    - LPIPS (state-of-the-art Perceptual Metric): <a href="https://richzhang.github.io/PerceptualSimilarity/">The Unreasonable Effectiveness of Deep Features as a Perceptual Metric</a>.
                    <br> <br>
                    - <a href="https://arxiv.org/abs/1911.11544">Image2StyleGAN++: How to Edit the Embedded Images?</a>
                </p>
            </div>
        </div>
        
            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{guarnizoreproduction,
    title={Reproduction of Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?},
    author={Guarnizo, Oscar}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p style="text-align: right">
                Powered by <a href="https://jonbarron.info/">Jon Barron</a> and <a href="http://mgharbi.com/">Michaël Gharbi</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
